#!/usr/bin/env bash
#SBATCH -J benchmark_parallel
#SBATCH -p gpu
#SBATCH -t 08:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=8gb
#SBATCH --array=1-250
#SBATCH --account dmobley_lab_gpu
#SBATCH --gres=gpu:V100:1
#SBATCH --export ALL
#SBATCH --requeue

# Set the output and error output paths.
#SBATCH -o  ./slurm_output/slurm-%J.out
#SBATCH -e  ./slurm_output/slurm-%J.err
#

module purge
module load cuda/11.7.1

module list 

mkdir -p 02-outputs
mkdir -p 03-outputs

. ~/.bashrc
# Use the right conda environment
conda activate /dfs4/dmobley-lab/pbehara/conda-env/espaloma030
#conda env export > conda_env.yaml
python 02-b-minimize.py -i 02-chunks/01-processed-qm-"$SLURM_ARRAY_TASK_ID".sdf -o 02-outputs/espaloma-0.3.0rc1-"$SLURM_ARRAY_TASK_ID".sdf

python 03-a-compute-metrics.py --input "03-force-fields.json" --index "$SLURM_ARRAY_TASK_ID" --output 03-outputs/03-metrics-"$SLURM_ARRAY_TASK_ID".csv

