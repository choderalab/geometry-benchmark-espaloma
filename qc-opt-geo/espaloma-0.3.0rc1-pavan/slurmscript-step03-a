#!/usr/bin/env bash
#SBATCH -J benchmark_parallel
#SBATCH -p standard
#SBATCH -t 8:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem-per-cpu=8gb
#SBATCH --array=1-250
#SBATCH --account dmobley_lab
#SBATCH --export ALL
#SBATCH --requeue
#SBATCH --constraint=fastscratch

# Set the output and error output paths.
#SBATCH -o  ./slurm_output/slurm-%J.out
#SBATCH -e  ./slurm_output/slurm-%J.err
#

mkdir -p 03-outputs


. ~/.bashrc
# Use the right conda environment
conda activate /dfs4/dmobley-lab/pbehara/conda-env/espaloma030

#conda env export > conda_env.yaml

python 03-a-compute-metrics.py --input "03-force-fields.json" --index "$SLURM_ARRAY_TASK_ID" --output 03-outputs/03-metrics-"$SLURM_ARRAY_TASK_ID".csv

#python 03-parameter-rmsd-compute-metrics.py --input "03-force-fields.json" --index "$SLURM_ARRAY_TASK_ID" --output 03-outputs/03-metrics-granular-"$SLURM_ARRAY_TASK_ID".csv

